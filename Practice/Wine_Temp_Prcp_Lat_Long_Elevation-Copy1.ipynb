{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the requests library.\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import the requests library.\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "# Dependencies for the wine API\n",
    "import urllib\n",
    "import json\n",
    "# Import the API key.\n",
    "from config import weather_api_key\n",
    "from config import Token_NOAA\n",
    "from config import API_Token\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/crvaden/NOAA_API_v2\n",
    "# https://towardsdatascience.com/getting-weather-data-in-3-easy-steps-8dc10cc5c859\n",
    "# https://cran.r-project.org/web/packages/rnoaa/rnoaa.pdf\n",
    "# file:///C:/Users/15124/Downloads/GHCND_documentation.pdf\n",
    "# https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Avg Temp and Precipitation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from noaa_api_v2 import NOAAData\n",
    "# api_token = Token_NOAA\n",
    "\n",
    "# data = NOAAData(api_token)\n",
    "\n",
    "# categories = data.data_categories(locationid='FIPS:37', sortfield='name')\n",
    "\n",
    "# for i in categories:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create average temperature\n",
    "\n",
    "# Create empty lists to append the data into\n",
    "dates_temp = []\n",
    "temps = []\n",
    "dates_prcp = []\n",
    "prcp = []\n",
    "\n",
    "#Identify what years we want Temp and Prcp data for\n",
    "for year in range(2013, 2017):\n",
    "    year = str(year)\n",
    "    #Print out 'working on year' to idenfity if script is running correctly\n",
    "    print('working on year '+year)\n",
    "    \n",
    "    #make the api call for temp and precipitation\n",
    "    r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=TAVG&limit=1000&stationid=GHCND:USW00023129&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #Load JSON data\n",
    "    d = json.loads(r.text)\n",
    "    e = json.loads(p.text)\n",
    "    #Get TAVG and PRCP data\n",
    "    avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "    avg_prcp = [item for item in e['results'] if item['datatype']=='PRCP']\n",
    "    #get the date field from all average temperature readings\n",
    "    dates_temp += [item['date'] for item in avg_temps]\n",
    "    dates_prcp += [item['date'] for item in avg_prcp]\n",
    "    #get the actual average temperature from all average temperature readings\n",
    "    temps += [item['value'] for item in avg_temps]\n",
    "    prcp += [item['value'] for item in avg_prcp]\n",
    "    \n",
    "# initialize dataframe\n",
    "df_temp = pd.DataFrame()\n",
    "df_prcp = pd.DataFrame()\n",
    "\n",
    "# populate date and average temperature fields (cast string date to datetime)\n",
    "df_temp['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_temp]\n",
    "df_prcp['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_prcp]\n",
    "# convert to degrees F\n",
    "df_temp['avgTemp'] = [float(v)/10.0*1.8 + 32 for v in temps]\n",
    "#convert to mm to inches\n",
    "df_prcp['avgPrcp'] = [float(v)*0.0393701 for v in prcp]\n",
    "# Average the temp/prcp per day to temp/prcp per month\n",
    "df_temp = df_temp.set_index('date').resample('M').mean()\n",
    "df_prcp = df_prcp.set_index('date').resample('M').mean()\n",
    "# Combine the series into a df\n",
    "df_temp['avgPrcp']=df_prcp['avgPrcp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Washington Avg Temp and Precipitation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-0e6cd59509c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m#         print(d)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;31m#Get TAVG and PRCP data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mavg_temps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'results'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datatype'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'TAVG'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0mavg_prcp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'results'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datatype'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'PRCP'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;31m#get the date field from all average temperature readings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'results'"
     ]
    }
   ],
   "source": [
    "#Create average temperature\n",
    "dates_temp_W = []\n",
    "temps_W = []\n",
    "dates_prcp_W = []\n",
    "prcp_W = []\n",
    "names=['Napa', 'Walla', 'Salem']\n",
    "zip_codes=['USW00023129', 'USW00023129', 'USW00023129']\n",
    "\n",
    "df_temp_W = pd.DataFrame()\n",
    "df_prcp_W = pd.DataFrame()\n",
    "\n",
    "\n",
    "temp_names=['avgTemp', 'avgTemp','avgTemp']\n",
    "temp=['Napa_temp','Napa_temp','Napa_temp',]\n",
    "prcp_names=['avgPrcp', 'avgPrcp', 'avgPrcp']\n",
    "prcp=['Napa_prcp', 'Napa_prcp', 'Napa_prcp']\n",
    "bigdf = pd.DataFrame()\n",
    "\n",
    "\n",
    "#for each year from 2015-2019 ...\n",
    "for i in range(len(zip_codes)):\n",
    "    zip_=zip_codes[i]\n",
    "    for year, temps, t, prcps, p in zip(range(1992, 2014),temp_names, temp, prcp_names, prcp):\n",
    "        for name in names:\n",
    "            year = str(year)\n",
    "            print('working on year '+year)\n",
    "\n",
    "            #make the api call for temp and precipitation\n",
    "            r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=TAVG&limit=1000&stationid=GHCND:{zip_}&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "            p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&limit=1000&stationid=GHCND:{zip_}&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "            #Load JSON data\n",
    "            d = json.loads(r.text)\n",
    "            e = json.loads(p.text)\n",
    "    #         print(d)\n",
    "            #Get TAVG and PRCP data\n",
    "            avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "            avg_prcp = [item for item in e['results'] if item['datatype']=='PRCP']\n",
    "            #get the date field from all average temperature readings\n",
    "            dates_temp_W += [item['date'] for item in avg_temps]\n",
    "            dates_prcp_W += [item['date'] for item in avg_prcp]\n",
    "            #get the actual average temperature from all average temperature readings\n",
    "            temps_W += [item['value'] for item in avg_temps]\n",
    "            prcp_W  += [item['value'] for item in avg_prcp]\n",
    "\n",
    "            #initialize dataframe\n",
    "            df_temp_W = pd.DataFrame()\n",
    "            df_prcp_W = pd.DataFrame()\n",
    "\n",
    "            #populate date and average temperature fields (cast string date to datetime\n",
    "            df_temp_W['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_temp_W]\n",
    "            df_prcp_W['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_prcp_W]\n",
    "            #convert to degrees F\n",
    "            df_temp_W['avgTemp'] = [float(v)/10.0*1.8 + 32 for v in temps_W]\n",
    "            #convert to mm to inches\n",
    "            df_prcp_W['avgPrcp'] = [float(v)*0.0393701 for v in prcp_W]\n",
    "            # Average the temp/prcp per day to temp/prcp per month\n",
    "            df_temp_W = df_temp_W.set_index('date').resample('M').mean()\n",
    "            df_prcp_W = df_prcp_W.set_index('date').resample('M').mean()\n",
    "            # Combine the series into a df\n",
    "            df_temp_W['avgPrcp']=df_prcp_W['avgPrcp']          \n",
    "#             df_temp_W.rename(columns={temps:t}, inplace=True)\n",
    "#             df_temp_W.rename(columns={prcps:p}, inplace=True)\n",
    "#             df_temp_W.reset_index(inplace=True)\n",
    "#             d=df_temp_W[['date', t, p]]\n",
    "#             bigdf['Date']=d['date']\n",
    "#             bigdf[t] = d[t]\n",
    "#             bigdf[p] = d[p]\n",
    "df_temp_W           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Napa_temp</th>\n",
       "      <th>&lt;Response [200]&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>62.678000</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>67.123226</td>\n",
       "      <td>0.213361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>68.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>70.316774</td>\n",
       "      <td>0.022860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-08-31</td>\n",
       "      <td>70.432903</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>72.326000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>65.950323</td>\n",
       "      <td>0.039370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-11-30</td>\n",
       "      <td>62.612000</td>\n",
       "      <td>0.261155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>57.072258</td>\n",
       "      <td>0.109220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Napa_temp  <Response [200]>\n",
       "0 2013-04-30  62.678000          0.007874\n",
       "1 2013-05-31  67.123226          0.213361\n",
       "2 2013-06-30  68.300000          0.000000\n",
       "3 2013-07-31  70.316774          0.022860\n",
       "4 2013-08-31  70.432903          0.000000\n",
       "5 2013-09-30  72.326000          0.000000\n",
       "6 2013-10-31  65.950323          0.039370\n",
       "7 2013-11-30  62.612000          0.261155\n",
       "8 2013-12-31  57.072258          0.109220"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_names=['avgTemp']\n",
    "temp=['Napa_temp', 'walla']\n",
    "prcp_names=['avgPrcp']\n",
    "prcp=['Napa_prcp']\n",
    "bigdf = pd.DataFrame()\n",
    "\n",
    "\n",
    "for temps, t, prcps,p in zip(temp_names, temp, prcp_names, prcp):\n",
    "    df_temp_W.rename(columns={temps:t}, inplace=True)\n",
    "    df_temp_W.rename(columns={prcps:p}, inplace=True)\n",
    "    df_temp_W.reset_index(inplace=True)\n",
    "#     d=df_temp_W[['date', t, p]]\n",
    "    bigdf['Date']=df_temp_W['date']\n",
    "    bigdf[t] = df_temp_W[t]\n",
    "    bigdf[p] = df_temp_W[p]\n",
    "bigdf\n",
    "#             d['Date']=pd.to_datetime(d['Date'], errors='coerce')\n",
    "#             bigdf['Date']=d['Date']\n",
    "#             bigdf[name] = d[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-ed8df0174584>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#Get TAVG and PRCP data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mavg_temps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'results'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datatype'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'TAVG'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mavg_prcp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'results'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datatype'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'PRCP'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m#get the date field from all average temperature readings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'results'"
     ]
    }
   ],
   "source": [
    "dates_temp_W = []\n",
    "temps_W = []\n",
    "dates_prcp_W = []\n",
    "prcp_W = []\n",
    "# names=['Napa', 'Walla', 'Salem']\n",
    "zip_codes=['USW00023129']\n",
    "\n",
    "df_temp_W = pd.DataFrame()\n",
    "df_prcp_W = pd.DataFrame()\n",
    "\n",
    "for year in range(1992, 2017):\n",
    "    year = str(year)\n",
    "    print('working on year '+year)\n",
    "\n",
    "    #make the api call for temp and precipitation\n",
    "    r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=TAVG&limit=1000&stationid=GHCND:USW00023129&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "    p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&limit=1000&stationid=GHCND:USW00023129&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "    #Load JSON data\n",
    "    d = json.loads(r.text)\n",
    "    e = json.loads(p.text)\n",
    "    #Get TAVG and PRCP data\n",
    "    avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "    avg_prcp = [item for item in e['results'] if item['datatype']=='PRCP']\n",
    "    #get the date field from all average temperature readings\n",
    "    dates_temp_W += [item['date'] for item in avg_temps]\n",
    "    dates_prcp_W += [item['date'] for item in avg_prcp]\n",
    "    #get the actual average temperature from all average temperature readings\n",
    "    temps_W += [item['value'] for item in avg_temps]\n",
    "    prcp_W  += [item['value'] for item in avg_prcp]\n",
    "\n",
    "#initialize dataframe\n",
    "df_temp_W = pd.DataFrame()\n",
    "df_prcp_W = pd.DataFrame()\n",
    "\n",
    "#populate date and average temperature fields (cast string date to datetime\n",
    "df_temp_W['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_temp_W]\n",
    "df_prcp_W['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_prcp_W]\n",
    "#convert to degrees F\n",
    "df_temp_W['avgTemp'] = [float(v)/10.0*1.8 + 32 for v in temps_W]\n",
    "#convert to mm to inches\n",
    "df_prcp_W['avgPrcp'] = [float(v)*0.0393701 for v in prcp_W]\n",
    "# Average the temp/prcp per day to temp/prcp per month\n",
    "df_temp_W = df_temp_W.set_index('date').resample('M').mean()\n",
    "df_prcp_W = df_prcp_W.set_index('date').resample('M').mean()\n",
    "# Combine the series into a df\n",
    "df_temp_W['avgPrcp']=df_prcp_W['avgPrcp']\n",
    "df_temp_W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Oregon Avg Temp and Precipitation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create average temperature\n",
    "dates_temp_O = []\n",
    "temps_O = []\n",
    "dates_prcp_O = []\n",
    "prcp_O = []\n",
    "\n",
    "#for each year from 2015-2019 ...\n",
    "for year in range(2013, 2014):\n",
    "    year = str(year)\n",
    "    print('working on year '+year)\n",
    "    \n",
    "    #make the api call\n",
    "    r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=TAVG&limit=1000&locationid=ZIP:28801&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "    p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&limit=1000&locationid=ZIP:28801&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "    #load the api response as a json\n",
    "    d = json.loads(r.text)\n",
    "    print(d)\n",
    "    e = json.loads(p.text)\n",
    "    #get all items in the response which are average temperature readings\n",
    "    avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "    avg_prcp = [item for item in e['results'] if item['datatype']=='PRCP']\n",
    "    #get the date field from all average temperature readings\n",
    "    dates_temp_O += [item['date'] for item in avg_temps]\n",
    "    dates_prcp_O += [item['date'] for item in avg_prcp]\n",
    "    #get the actual average temperature from all average temperature readings\n",
    "    temps_O += [item['value'] for item in avg_temps]\n",
    "    prcp_O += [item['value'] for item in avg_prcp]\n",
    "\n",
    "#initialize dataframe\n",
    "df_temp_O = pd.DataFrame()\n",
    "df_prcp_O = pd.DataFrame()\n",
    "\n",
    "#populate date and average temperature fields (cast string date to datetime\n",
    "df_temp_O['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_temp_O]\n",
    "df_prcp_O['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_prcp_O]\n",
    "#convert to degrees F\n",
    "df_temp_O['avgTemp'] = [float(v)/10.0*1.8 + 32 for v in temps_O]\n",
    "#convert to mm to inches\n",
    "df_prcp_O['avgPrcp'] = [float(v)*0.0393701 for v in prcp_O]\n",
    "# Average the temp/prcp per day to temp/prcp per month\n",
    "df_temp_O = df_temp_O.set_index('date').resample('M').mean()\n",
    "df_prcp_O = df_prcp_O.set_index('date').resample('M').mean()\n",
    "# Combine the series into a df\n",
    "df_temp_O['avgPrcp']=df_prcp_O['avgPrcp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Lat/Long/Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns for Lat/Long/Elevation for the red and white white data\n",
    "#There are three clusters of wineries. \n",
    "#The wineries in California, Washington, and Oregon are within a couple dozen miles of one another in each state.\n",
    "#So I just used three stations: One for California, one for Washington, one for Oregon\n",
    "\n",
    "\n",
    "#-------------------------------------------------------Station IDs---------------------------------------------------#\n",
    "#California_GHCND:\n",
    "Nappa_Valley_g='GHCND:USC00046074'\n",
    "# Washington_GHCND:\n",
    "Walla_Walla_Valley_g='GHCND:GHCND:USC00457015'\n",
    "# Oregon_GHCND:\n",
    "Willamette_Valley_g='GHCND:USW00024232'\n",
    "#--------------------------------------------------------Latitude-----------------------------------------------------#\n",
    "\n",
    "#Latitude\n",
    "#California_LAT:\n",
    "Cali_lat='38.2777'\n",
    "# Oregon_lat:\n",
    "Oregon_lat='44.905'\n",
    "# Washington_Lat:\n",
    "Washington_lat='46.3119'\n",
    "\n",
    "\n",
    "#Create a new column in red_USA_df that has latitude for california, washingtion, oregon\n",
    "latitude=[]\n",
    "for lat in red_USA_df['regions']:\n",
    "#California\n",
    "    if lat =='California':\n",
    "        latitude.append(Cali_lat)\n",
    "#Oregon\n",
    "    elif lat == 'Oregon':\n",
    "        latitude.append(Oregon_lat)\n",
    "#Washington\n",
    "    else:\n",
    "        latitude.append(Washington_lat)\n",
    "red_USA_df['lat']=latitude\n",
    "\n",
    "#Create a new column in white_USA_df that has latitude for california, washingtion, oregon\n",
    "latitude=[]\n",
    "for lat in white_USA_df['regions']:\n",
    "#California\n",
    "    if lat =='California':\n",
    "        latitude.append(Cali_lat)\n",
    "#Oregon\n",
    "    elif lat == 'Oregon':\n",
    "        latitude.append(Oregon_lat)\n",
    "#Washington\n",
    "    else:\n",
    "        latitude.append(Washington_lat)\n",
    "white_USA_df['lat']=latitude\n",
    "\n",
    "#------------------------------------------------------Longitude-------------------------------------------------------------#\n",
    "\n",
    "#Longitude\n",
    "#California_Long:\n",
    "Cali_long='-122.2647'\n",
    "# Oregon_Long:\n",
    "Oregon_long='-123.0011'\n",
    "# Washington_Long:\n",
    "Washington_long= '-119.2633'\n",
    "\n",
    "#Create a new column in red_USA_df that has longitude for california, washingtion, oregon\n",
    "longitude=[]\n",
    "for long in red_USA_df['regions']:\n",
    "#California\n",
    "    if long =='California':\n",
    "        longitude.append(Cali_long)\n",
    "#Oregon\n",
    "    elif long == 'Oregon':\n",
    "        longitude.append(Oregon_long)\n",
    "#Washington\n",
    "    else:\n",
    "        longitude.append(Washington_long)\n",
    "red_USA_df['long']=longitude \n",
    "\n",
    "#Create a new column in white_USA_df that has longitude for california, washingtion, oregon\n",
    "longitude=[]\n",
    "for long in white_USA_df['regions']:\n",
    "#California\n",
    "    if long =='California':\n",
    "        longitude.append(Cali_long)\n",
    "#Oregon\n",
    "    elif long == 'Oregon':\n",
    "        longitude.append(Oregon_long)\n",
    "#Washington\n",
    "    else:\n",
    "        longitude.append(Washington_long)\n",
    "white_USA_df['long']=longitude \n",
    "\n",
    "#-----------------------------------------------------------------Elevation------------------------------------------------#\n",
    "\n",
    "#Elevation (feet)\n",
    "#California_Elevation:\n",
    "Cali_ele='35.1'\n",
    "# Oregon_Elevation:\n",
    "Oregon_ele='205.1'\n",
    "# Washington_Elevation:\n",
    "Washington_ele= '631.9'\n",
    "\n",
    "\n",
    "#Create a new column in red_USA_df that has elevation for california, washingtion, oregon\n",
    "elevation=[]\n",
    "for ele in red_USA_df['regions']:\n",
    "#California\n",
    "    if ele =='California':\n",
    "        elevation.append(Cali_ele)\n",
    "#Oregon\n",
    "    elif ele == 'Oregon':\n",
    "        elevation.append(Oregon_ele)\n",
    "#Washington\n",
    "    else:\n",
    "        elevation.append(Washington_ele)\n",
    "red_USA_df['elevation']=elevation\n",
    "\n",
    "#Create a new column in white_USA_df that has elevation for california, washingtion, oregon\n",
    "elevation=[]\n",
    "for ele in white_USA_df['regions']:\n",
    "#California\n",
    "    if ele =='California':\n",
    "        elevation.append(Cali_ele)\n",
    "#Oregon\n",
    "    elif ele == 'Oregon':\n",
    "        elevation.append(Oregon_ele)\n",
    "#Washington\n",
    "    else:\n",
    "        elevation.append(Washington_ele)\n",
    "white_USA_df['elevation']=elevation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_USA_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station, year in zip(white_USA_df['appellation'], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Temp/Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the date into columns for days, months, years and then drop days columns for each of the three states\n",
    "#-------------------------------------------------------------------------------California----------------------------\n",
    "df_temp.reset_index(inplace= True )\n",
    "df_temp['day'] = df_temp['date'].dt.day\n",
    "df_temp['month'] = df_temp['date'].dt.month\n",
    "df_temp['year'] = df_temp['date'].dt.year\n",
    "\n",
    "list_months=[]\n",
    "for x in df_temp['month']:\n",
    "    list_months.append(calendar.month_name[x])\n",
    "df_temp['months']=list_months\n",
    "df_temp.drop(['date', 'day','month'], axis=1, inplace=True)\n",
    "df_temp\n",
    "#----------------------------------------------------------------------------------Oregon-------------------------------\n",
    "# df_temp_O.reset_index(inplace= True )\n",
    "# df_temp_O['day'] = df_temp_O['date'].dt.day\n",
    "# df_temp_O['month'] = df_temp_O['date'].dt.month\n",
    "# df_temp_O['year'] = df_temp_O['date'].dt.year\n",
    "\n",
    "# list_months=[]\n",
    "# for x in df_temp_O['month']:\n",
    "#     list_months.append(calendar.month_name[x])\n",
    "# df_temp_O['months']=list_months\n",
    "# df_temp_O.drop(['date', 'day','month'], axis=1, inplace=True)\n",
    "# #-----------------------------------------------------------------------------------Washington---------------------\n",
    "# df_temp_W.reset_index(inplace= True )\n",
    "# df_temp_W['day'] = df_temp_W['date'].dt.day\n",
    "# df_temp_W['month'] = df_temp_W['date'].dt.month\n",
    "# df_temp_W['year'] = df_temp_W['date'].dt.year\n",
    "\n",
    "# list_months=[]\n",
    "# for x in df_temp_W['month']:\n",
    "#     list_months.append(calendar.month_name[x])\n",
    "# df_temp_W['months']=list_months\n",
    "# df_temp_W.drop(['date', 'day','month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_USA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calender_years=[2013, 2014,2015, 2016, 2017]\n",
    "calender_months=['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_2013=[]\n",
    "# temp_2014=[]\n",
    "# temp_2015=[]\n",
    "# temp_2016=[]\n",
    "# temp_2017=[]\n",
    "# temp_2018=[]\n",
    "# garbage=[]\n",
    "# prcp_2013=[]\n",
    "# prcp_2014=[]\n",
    "# prcp_2015=[]\n",
    "# prcp_2016=[]\n",
    "# prcp_2017=[]\n",
    "# prcp_2018=[]\n",
    "\n",
    "# for temp, prcp, year, month in zip(df_temp['avgTemp'], df_temp['avgPrcp'], df_temp['year'], df_temp['months']):\n",
    "#     if year==2013:\n",
    "#         temp_2013.append(temp)    \n",
    "#     elif year==2014:\n",
    "#         temp_2014.append(temp)\n",
    "#     elif year==2015:\n",
    "#         temp_2015.append(temp)\n",
    "#     elif year==2016:\n",
    "#         temp_2016.append(temp)\n",
    "#     elif year==2017:\n",
    "#         temp_2017.append(temp)\n",
    "#     else:\n",
    "#         garbage.append(temp)\n",
    "\n",
    "# for temp, prcp, year, month in zip(df_temp['avgTemp'], df_temp['avgPrcp'], df_temp['year'], df_temp['months']):\n",
    "#     if year==2013:\n",
    "#         prcp_2013.append(temp)    \n",
    "#     elif year==2014:\n",
    "#         prcp_2014.append(temp)\n",
    "#     elif year==2015:\n",
    "#         prcp_2015.append(temp)\n",
    "#     elif year==2016:\n",
    "#         prcp_2016.append(temp)\n",
    "#     elif year==2017:\n",
    "#         prcp_2017.append(temp)\n",
    "#     else:\n",
    "#         garbage.append(temp)\n",
    "# temp_2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# march_2016=[]\n",
    "# april_2016=[]\n",
    "# may_2016=[]\n",
    "# june_2016=[]\n",
    "# july_2016=[]\n",
    "# august_2016=[]\n",
    "# september_2016=[]\n",
    "\n",
    "\n",
    "# for region,vint,year  in zip(white_USA_df['regions'],white_USA_df['vintage'],temp_2016):\n",
    "#     if region=='California' and vint==2016:\n",
    "#         march_2016.append(temp_2016[3])\n",
    "#     elif region=='California' and vint==2016:\n",
    "#         april_2016.append(temp_2016[4])\n",
    "#     elif region=='California' and vint==2016:\n",
    "#         may_2016.append(temp_2016[5])        \n",
    "#     elif region=='California' and vint==2016:\n",
    "#         june_2016.append(temp_2016[6])        \n",
    "#     elif region=='California' and vint==2016:\n",
    "#         july_2016.append(temp_2016[7])        \n",
    "#     elif region=='California' and vint==2016:\n",
    "#         august_2016.append(temp_2016[8])        \n",
    "#     elif region=='California' and vint==2016:\n",
    "#         september_2016.append(temp_2016[9])   \n",
    "#     else:\n",
    "#         garbage.append(0)\n",
    "# march_2016        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_temp_march=[]\n",
    "# all_months=[]\n",
    "\n",
    "# for region,vint,year, temp, month, cyears, cmonths  in zip(white_USA_df['regions'],white_USA_df['vintage'],df_temp['year'], df_temp['avgTemp'], df_temp['months'], calender_years, calender_months):\n",
    "#     if region=='California' and vint==2016:\n",
    "#             list_temp_march.append(temp)\n",
    "#         else:\n",
    "#             list_temp_march.append(0)\n",
    "#     else:list_2016=[]\n",
    "# march_2016=[]\n",
    "# april_2016=[]\n",
    "# may_2016=[]\n",
    "# june_2016=[]\n",
    "# july_2016=[]\n",
    "# august_2016=[]\n",
    "# september_2016=[]\n",
    "# for region,vint,years,temps,month in zip(white_USA_df['regions'],white_USA_df['vintage'],df_temp['year'], df_temp['avgTemp'], df_temp['months']):\n",
    "#     if vint==2016 and region=='Calfornia' and month=='March':\n",
    "#         march_2016.append(temps)\n",
    "#     elif vint==2016 and region=='Calfornia' and month=='April':\n",
    "#         april_2016.append(temps)\n",
    "#     elif vint==2016 and region=='Calfornia' and month=='May':\n",
    "#         may_2016.append(temps)\n",
    "#     elif vint==2016 and region=='Calfornia' and month=='June':\n",
    "#         june_2016.append(temps)\n",
    "#     elif vint==2016 and region=='Calfornia' and month=='July':\n",
    "#         july_2016.append(temps)\n",
    "#     elif vint==2016 and region=='Calfornia' and month=='August':\n",
    "#         august_2016.append(temps)\n",
    "#     elif vint==2016 and region=='Calfornia' and month=='September':\n",
    "#         september_2016.append(temps) \n",
    "#         list_temp_march.append(1)\n",
    "# list_temp_march\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_2016=[]\n",
    "# march_2016=[]\n",
    "# april_2016=[]\n",
    "# may_2016=[]\n",
    "# june_2016=[]\n",
    "# july_2016=[]\n",
    "# august_2016=[]\n",
    "# september_2016=[]\n",
    "# for region,vint,years,temps,month in zip(white_USA_df['regions'],white_USA_df['vintage'],df_temp['year'], df_temp['avgTemp'], df_temp['months']):\n",
    "#     if vint==2016 and region=='Calfornia' and month=='March':\n",
    "#         march_2016.append(temps)\n",
    "#     elif vint==2016 and region=='Calfornia' and month=='April':\n",
    "#         april_2016.append(temps)\n",
    "#     elif vint==2016 and region=='Calfornia' and month=='May':\n",
    "#         may_2016.append(temps)\n",
    "#     elif vint==2016 and region=='Calfornia' and month=='June':\n",
    "#         june_2016.append(temps)\n",
    "#     elif vint==2016 and region=='Calfornia' and month=='July':\n",
    "#         july_2016.append(temps)\n",
    "#     elif vint==2016 and region=='Calfornia' and month=='August':\n",
    "#         august_2016.append(temps)\n",
    "#     elif vint==2016 and region=='Calfornia' and month=='September':\n",
    "#         september_2016.append(temps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# white_USA_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Trying to add columns for weather data for each month\n",
    "\n",
    "# list_temp_march=[]\n",
    "# # def monthData (year, month, region, vintage):\n",
    "# for u,v,x,y,z in zip(white_USA_df['regions'],white_USA_df['vintage'],df_temp['year'], df_temp['avgTemp'], df_temp['months']):\n",
    "#     if v==2016 and v==2016 and u=='California'and z=='March':\n",
    "#         list_temp_march.append(y)\n",
    "#     #elif y==z and y==2016 and x=='Oregon'and v=='April':\n",
    "#         #list_temp_march.append(u)\n",
    "#     else:\n",
    "#         list_temp_march.append(0)\n",
    "            \n",
    "# # white_USA_df['march']= list_temp_march         \n",
    "# # white_USA_df['march']=white_USA_df['march'].apply(monthData)\n",
    "# # list_temp_march    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Trying to add columns for weather data for each month\n",
    "# list_temp_march=[]\n",
    "# march_2016=[]\n",
    "# april_2016=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # def monthData (year, month, region, vintage):\n",
    "# for u,v,x,y,z in zip(white_USA_df['regions'],white_USA_df['vintage'],df_temp['year'], df_temp['avgTemp'], df_temp['months']):\n",
    "#     if v==2016 and v==2016 and u=='California':\n",
    "#         list_temp_march.append(y)\n",
    "#     #elif y==z and y==2016 and x=='Oregon'and v=='April':\n",
    "#         #list_temp_march.append(u)\n",
    "#     else:\n",
    "#         list_temp_march.append(0)\n",
    "            \n",
    "# # white_USA_df['march']= list_temp_march         \n",
    "# # white_USA_df['march']=white_USA_df['march'].apply(monthData)\n",
    "# list_temp_march"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_red_USA_df=red_USA_df.sort_values(by=['regions'], ascending=False)\n",
    "sorted_red_USA_df=sorted_red_USA_df[sorted_red_USA_df['regions']=='Oregon']\n",
    "sorted_red_USA_df=sorted_red_USA_df.sort_values(by=['vintage'], ascending=True)\n",
    "sorted_red_USA_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imported dependencies<p>\n",
    "Used the Global Wine Score API to import data for red and white wine in the USA<p>\n",
    "Imported weather data for California, Oregon, Washington<p>\n",
    "Added new columns Latitude, Longitude, and Elevation to red and white wine dataframes<p>\n",
    "Finally I am trying to add new columns for monthly weather data to the red and white wine dataframes<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # .apply() method\n",
    "# white_USA_df['march']=[]\n",
    "\n",
    "#axis=1 for columns\n",
    "#default--->result_type=None means that final return type is inferred (default)\n",
    "#raw is false means that it will be a series, True is it is an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
