{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the requests library.\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import the requests library.\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "# Dependencies for the wine API\n",
    "import urllib\n",
    "import json\n",
    "# Import the API key.\n",
    "from config import Token_NOAA\n",
    "from config import API_Token\n",
    "import calendar\n",
    "#Suppress Warnings\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "#Display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/crvaden/NOAA_API_v2\n",
    "# https://towardsdatascience.com/getting-weather-data-in-3-easy-steps-8dc10cc5c859\n",
    "# https://cran.r-project.org/web/packages/rnoaa/rnoaa.pdf\n",
    "# file:///C:/Users/15124/Downloads/GHCND_documentation.pdf\n",
    "# https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data By Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "napadf = pd.DataFrame()\n",
    "states = {\n",
    "    'Napa': {\n",
    "        'zip': '94559',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97302',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n",
      "working on year 1993\n",
      "working on year 1994\n",
      "working on year 1995\n",
      "working on year 1996\n",
      "working on year 1997\n",
      "working on year 1998\n",
      "working on year 1999\n",
      "working on year 2000\n",
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n",
      "working on year 2016\n",
      "working on year 2017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>PRCPNapa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-01-04</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992-01-05</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>2017-12-16</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>2017-12-16</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9985 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  PRCPNapa\n",
       "0    1992-01-01      0.00\n",
       "1    1992-01-02      0.00\n",
       "2    1992-01-03      0.00\n",
       "3    1992-01-04      0.21\n",
       "4    1992-01-05      1.32\n",
       "..          ...       ...\n",
       "662  2017-12-15      0.00\n",
       "663  2017-12-16      0.00\n",
       "664  2017-12-16      0.00\n",
       "665  2017-12-17      0.00\n",
       "666  2017-12-17      0.00\n",
       "\n",
       "[9985 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=PRCP&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='PRCP']\n",
    "#         items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "#         dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['PRCP'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['PRCP'+state]] = item['value']\n",
    "#         df_test['avgMinTemp'+state] = np.nan\n",
    "#         for item in items_MIN:\n",
    "#             date = item['date'].split('T')[0]\n",
    "#             df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if napadf.empty:\n",
    "        napadf = small_df\n",
    "    else:\n",
    "        napadf = pd.merge(napadf,small_df)\n",
    "napadf.to_csv( 'Napa_Prcp.csv', index = False)\n",
    "napadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "walladf = pd.DataFrame()\n",
    "states = {\n",
    "    'Napa': {\n",
    "        'zip': '95472',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97302',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n",
      "working on year 1993\n",
      "working on year 1994\n",
      "working on year 1995\n",
      "working on year 1996\n",
      "working on year 1997\n",
      "working on year 1998\n",
      "working on year 1999\n",
      "working on year 2000\n",
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n",
      "working on year 2016\n",
      "working on year 2017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>PRCPWalla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-01-04</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992-01-05</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>2017-12-05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>2017-12-06</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>2017-12-06</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11526 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  PRCPWalla\n",
       "0    1992-01-01       0.00\n",
       "1    1992-01-02       0.08\n",
       "2    1992-01-03       0.00\n",
       "3    1992-01-04       0.12\n",
       "4    1992-01-05       0.12\n",
       "..          ...        ...\n",
       "654  2017-12-05       0.00\n",
       "655  2017-12-06       0.00\n",
       "656  2017-12-06       0.00\n",
       "657  2017-12-07       0.00\n",
       "658  2017-12-07       0.00\n",
       "\n",
       "[11526 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=PRCP&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='PRCP']\n",
    "#         items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "#         dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['PRCP'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['PRCP'+state]] = item['value']\n",
    "#         df_test['avgMinTemp'+state] = np.nan\n",
    "#         for item in items_MIN:\n",
    "#             date = item['date'].split('T')[0]\n",
    "#             df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if walladf.empty:\n",
    "        walladf = small_df\n",
    "    else:\n",
    "        walladf = pd.merge(walladf,small_df)\n",
    "walladf.to_csv( 'Walla_Prcp.csv', index = False)\n",
    "walladf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>PRCPWalla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-01-04</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992-01-05</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1992-01-06</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1992-01-07</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1992-01-08</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1992-01-09</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1992-01-10</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1992-01-11</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1992-01-12</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1992-01-13</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1992-01-14</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1992-01-15</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1992-01-16</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1992-01-17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1992-01-18</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1992-01-19</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1992-01-20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1992-01-21</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1992-01-22</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1992-01-23</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1992-01-24</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1992-01-25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1992-01-26</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1992-01-27</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1992-01-28</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1992-01-29</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1992-01-30</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1992-02-01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1992-02-02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1992-02-03</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1992-02-04</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1992-02-05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1992-02-06</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1992-02-07</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1992-02-08</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1992-02-09</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1992-02-10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1992-02-11</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1992-02-12</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1992-02-13</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1992-02-14</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1992-02-15</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1992-02-16</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1992-02-17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1992-02-18</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1992-02-19</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1992-02-20</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  PRCPWalla\n",
       "0   1992-01-01       0.00\n",
       "1   1992-01-02       0.08\n",
       "2   1992-01-03       0.00\n",
       "3   1992-01-04       0.12\n",
       "4   1992-01-05       0.12\n",
       "5   1992-01-06       0.00\n",
       "6   1992-01-07       0.00\n",
       "7   1992-01-08       0.00\n",
       "8   1992-01-09       0.00\n",
       "9   1992-01-10       0.10\n",
       "10  1992-01-11       0.00\n",
       "11  1992-01-12       0.00\n",
       "12  1992-01-13       0.00\n",
       "13  1992-01-14       0.00\n",
       "14  1992-01-15       0.00\n",
       "15  1992-01-16       0.12\n",
       "16  1992-01-17       0.00\n",
       "17  1992-01-18       0.00\n",
       "18  1992-01-19       0.00\n",
       "19  1992-01-20       0.00\n",
       "20  1992-01-21       0.00\n",
       "21  1992-01-22       0.00\n",
       "22  1992-01-23       0.00\n",
       "23  1992-01-24       0.01\n",
       "24  1992-01-25       0.00\n",
       "25  1992-01-26       0.00\n",
       "26  1992-01-27       0.10\n",
       "27  1992-01-28       0.26\n",
       "28  1992-01-29       0.05\n",
       "29  1992-01-30       0.01\n",
       "30  1992-02-01       0.00\n",
       "31  1992-02-02       0.00\n",
       "32  1992-02-03       0.00\n",
       "33  1992-02-04       0.00\n",
       "34  1992-02-05       0.00\n",
       "35  1992-02-06       0.00\n",
       "36  1992-02-07       0.06\n",
       "37  1992-02-08       0.08\n",
       "38  1992-02-09       0.04\n",
       "39  1992-02-10       0.00\n",
       "40  1992-02-11       0.00\n",
       "41  1992-02-12       0.00\n",
       "42  1992-02-13       0.01\n",
       "43  1992-02-14       0.02\n",
       "44  1992-02-15       0.07\n",
       "45  1992-02-16       0.01\n",
       "46  1992-02-17       0.00\n",
       "47  1992-02-18       0.12\n",
       "48  1992-02-19       0.08\n",
       "49  1992-02-20       0.60"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walladf.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columbiadf = pd.DataFrame()\n",
    "states = {\n",
    "    'Napa': {\n",
    "        'zip': '95472',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97302',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n",
      "working on year 1993\n",
      "working on year 1994\n",
      "working on year 1995\n",
      "working on year 1996\n",
      "working on year 1997\n",
      "working on year 1998\n",
      "working on year 1999\n",
      "working on year 2000\n",
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n",
      "working on year 2016\n",
      "working on year 2017\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=PRCP&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='PRCP']\n",
    "#         items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "#         dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['PRCP'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['PRCP'+state]] = item['value']\n",
    "#         df_test['avgMinTemp'+state] = np.nan\n",
    "#         for item in items_MIN:\n",
    "#             date = item['date'].split('T')[0]\n",
    "#             df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if columbiadf.empty:\n",
    "        columbiadf = small_df\n",
    "    else:\n",
    "        columbiadf = pd.merge(columbiadf,small_df)\n",
    "columbiadf.to_csv( 'Columbia_Prcp.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonomadf = pd.DataFrame()\n",
    "states = {\n",
    "    'Napa': {\n",
    "        'zip': '95472',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97302',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n",
      "working on year 1993\n",
      "working on year 1994\n",
      "working on year 1995\n",
      "working on year 1996\n",
      "working on year 1997\n",
      "working on year 1998\n",
      "working on year 1999\n",
      "working on year 2000\n",
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n",
      "working on year 2016\n",
      "working on year 2017\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=PRCP&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='PRCP']\n",
    "#         items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "#         dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['PRCP'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['PRCP'+state]] = item['value']\n",
    "#         df_test['avgMinTemp'+state] = np.nan\n",
    "#         for item in items_MIN:\n",
    "#             date = item['date'].split('T')[0]\n",
    "#             df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if sonomadf.empty:\n",
    "        sonomadf = small_df\n",
    "    else:\n",
    "        sonomadf = pd.merge(sonomadf,small_df)\n",
    "sonomadf.to_csv( 'Sonoma_Prcp.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "santadf = pd.DataFrame()\n",
    "states = {\n",
    "    'Napa': {\n",
    "        'zip': '95472',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97302',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n",
      "working on year 1993\n",
      "working on year 1994\n",
      "working on year 1995\n",
      "working on year 1996\n",
      "working on year 1997\n",
      "working on year 1998\n",
      "working on year 1999\n",
      "working on year 2000\n",
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n",
      "working on year 2016\n",
      "working on year 2017\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=PRCP&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='PRCP']\n",
    "#         items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "#         dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['PRCP'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['PRCP'+state]] = item['value']\n",
    "#         df_test['avgMinTemp'+state] = np.nan\n",
    "#         for item in items_MIN:\n",
    "#             date = item['date'].split('T')[0]\n",
    "#             df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if santadf.empty:\n",
    "        santadf = small_df\n",
    "    else:\n",
    "        santadf = pd.merge(santadf,small_df)\n",
    "santadf.to_csv( 'Santa_Prcp.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "yakimadf = pd.DataFrame()\n",
    "states = {\n",
    "    'Napa': {\n",
    "        'zip': '95472',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97302',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n",
      "working on year 1993\n",
      "working on year 1994\n",
      "working on year 1995\n",
      "working on year 1996\n",
      "working on year 1997\n",
      "working on year 1998\n",
      "working on year 1999\n",
      "working on year 2000\n",
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n",
      "working on year 2016\n",
      "working on year 2017\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=PRCP&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='PRCP']\n",
    "#         items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "#         dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['PRCP'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['PRCP'+state]] = item['value']\n",
    "#         df_test['avgMinTemp'+state] = np.nan\n",
    "#         for item in items_MIN:\n",
    "#             date = item['date'].split('T')[0]\n",
    "#             df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if yakimadf.empty:\n",
    "        yakimadf = small_df\n",
    "    else:\n",
    "        yakimadf = pd.merge(yakimadf,small_df)\n",
    "yakimadf.to_csv( 'Yakima_Prcp.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dundeedf = pd.DataFrame()\n",
    "states = {\n",
    "#     'Napa': {\n",
    "#         'zip': '95472',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "    'Dundee': {\n",
    "        'zip': '97148',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97302',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n",
      "working on year 1993\n",
      "working on year 1994\n",
      "working on year 1995\n",
      "working on year 1996\n",
      "working on year 1997\n",
      "working on year 1998\n",
      "working on year 1999\n",
      "working on year 2000\n",
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n",
      "working on year 2016\n",
      "working on year 2017\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=PRCP&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='PRCP']\n",
    "#         items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "#         dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['PRCP'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['PRCP'+state]] = item['value']\n",
    "#         df_test['avgMinTemp'+state] = np.nan\n",
    "#         for item in items_MIN:\n",
    "#             date = item['date'].split('T')[0]\n",
    "#             df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if dundeedf.empty:\n",
    "        dundeedf = small_df\n",
    "    else:\n",
    "        dundeedf = pd.merge(dundeedf,small_df)\n",
    "dundeedf.to_csv( 'Dundee_Prcp.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "willamettedf = pd.DataFrame()\n",
    "states = {\n",
    "#     'Napa': {\n",
    "#         'zip': '94558',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "    'Willamette': {\n",
    "        'zip': '97301',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-b24eb95e8dbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m#     print(d)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#e = json.loads(p.text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mitems_MAX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'results'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datatype'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'PRCP'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m#         items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# #get the date field from all average temperature readings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'results'"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=PRCP&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='PRCP']\n",
    "#         items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "#         dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['PRCP'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['PRCP'+state]] = item['value']\n",
    "#         df_test['avgMinTemp'+state] = np.nan\n",
    "#         for item in items_MIN:\n",
    "#             date = item['date'].split('T')[0]\n",
    "#             df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if willamettedf.empty:\n",
    "        willamettedf = small_df\n",
    "    else:\n",
    "        willamettedf = pd.merge(willamettedf,small_df)\n",
    "willamettedf.to_csv( 'Willamette_Prcp.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "willamettedf.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
