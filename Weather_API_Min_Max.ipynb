{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the requests library.\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import the requests library.\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "# Dependencies for the wine API\n",
    "import urllib\n",
    "import json\n",
    "# Import the API key.\n",
    "from config import Token_NOAA\n",
    "from config import API_Token\n",
    "import calendar\n",
    "#Suppress Warnings\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "#Display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/crvaden/NOAA_API_v2\n",
    "# https://towardsdatascience.com/getting-weather-data-in-3-easy-steps-8dc10cc5c859\n",
    "# https://cran.r-project.org/web/packages/rnoaa/rnoaa.pdf\n",
    "# file:///C:/Users/15124/Downloads/GHCND_documentation.pdf\n",
    "# https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data By Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "napadf = pd.DataFrame()\n",
    "states = {\n",
    "    'Napa': {\n",
    "        'zip': '95472',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97302',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n",
      "working on year 1993\n",
      "working on year 1994\n",
      "working on year 1995\n",
      "working on year 1996\n",
      "working on year 1997\n",
      "working on year 1998\n",
      "working on year 1999\n",
      "working on year 2000\n",
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n",
      "working on year 2016\n",
      "working on year 2017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avgMaxTempNapa</th>\n",
       "      <th>avgMinTempNapa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>59.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>58.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>55.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-01-04</td>\n",
       "      <td>58.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992-01-05</td>\n",
       "      <td>55.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>65.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>64.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>66.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>64.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>64.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9495 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  avgMaxTempNapa  avgMinTempNapa\n",
       "0    1992-01-01            59.0            29.0\n",
       "1    1992-01-02            58.0            29.0\n",
       "2    1992-01-03            55.0            30.0\n",
       "3    1992-01-04            58.0            39.0\n",
       "4    1992-01-05            55.0            43.0\n",
       "..          ...             ...             ...\n",
       "360  2017-12-27            65.0            33.0\n",
       "361  2017-12-28            64.0            35.0\n",
       "362  2017-12-29            66.0            32.0\n",
       "363  2017-12-30            64.0            28.0\n",
       "364  2017-12-31            64.0            28.0\n",
       "\n",
       "[9495 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if napadf.empty:\n",
    "        napadf = small_df\n",
    "    else:\n",
    "        napadf = pd.merge(napadf,small_df)\n",
    "napadf.to_csv( 'Napa_Max_Min.csv', index = False)\n",
    "napadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "walladf = pd.DataFrame()\n",
    "states = {\n",
    "    'Napa': {\n",
    "        'zip': '95472',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97302',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n",
      "working on year 1993\n",
      "working on year 1994\n",
      "working on year 1995\n",
      "working on year 1996\n",
      "working on year 1997\n",
      "working on year 1998\n",
      "working on year 1999\n",
      "working on year 2000\n",
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n",
      "working on year 2016\n",
      "working on year 2017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avgMaxTempWalla</th>\n",
       "      <th>avgMinTempWalla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>45.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>40.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-01-04</td>\n",
       "      <td>42.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992-01-05</td>\n",
       "      <td>39.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>34.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>41.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>40.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9446 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  avgMaxTempWalla  avgMinTempWalla\n",
       "0    1992-01-01             33.0             28.0\n",
       "1    1992-01-02             45.0             30.0\n",
       "2    1992-01-03             40.0             31.0\n",
       "3    1992-01-04             42.0             29.0\n",
       "4    1992-01-05             39.0             28.0\n",
       "..          ...              ...              ...\n",
       "360  2017-12-27             27.0             23.0\n",
       "361  2017-12-28             31.0             23.0\n",
       "362  2017-12-29             34.0             28.0\n",
       "363  2017-12-30             41.0             33.0\n",
       "364  2017-12-31             40.0             26.0\n",
       "\n",
       "[9446 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if walladf.empty:\n",
    "        walladf = small_df\n",
    "    else:\n",
    "        walladf = pd.merge(walladf,small_df)\n",
    "walladf.to_csv( 'Walla_Max_Min.csv', index = False)\n",
    "walladf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columbiadf = pd.DataFrame()\n",
    "states = {\n",
    "    'Napa': {\n",
    "        'zip': '95472',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97302',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n",
      "working on year 1993\n",
      "working on year 1994\n",
      "working on year 1995\n",
      "working on year 1996\n",
      "working on year 1997\n",
      "working on year 1998\n",
      "working on year 1999\n",
      "working on year 2000\n",
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n",
      "working on year 2016\n",
      "working on year 2017\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if columbiadf.empty:\n",
    "        columbiadf = small_df\n",
    "    else:\n",
    "        columbiadf = pd.merge(columbiadf,small_df)\n",
    "columbiadf.to_csv( 'Columbia_Max_Min.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonomadf = pd.DataFrame()\n",
    "states = {\n",
    "    'Napa': {\n",
    "        'zip': '95472',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97302',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n",
      "working on year 1993\n",
      "working on year 1994\n",
      "working on year 1995\n",
      "working on year 1996\n",
      "working on year 1997\n",
      "working on year 1998\n",
      "working on year 1999\n",
      "working on year 2000\n",
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n",
      "working on year 2016\n",
      "working on year 2017\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if sonomadf.empty:\n",
    "        sonomadf = small_df\n",
    "    else:\n",
    "        sonomadf = pd.merge(sonomadf,small_df)\n",
    "sonomadf.to_csv( 'Sonoma_Max_Min.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "santadf = pd.DataFrame()\n",
    "states = {\n",
    "#     'Napa': {\n",
    "#         'zip': '95472',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "    'Santa': {\n",
    "        'zip': '95062',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97302',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n",
      "working on year 1993\n",
      "working on year 1994\n",
      "working on year 1995\n",
      "working on year 1996\n",
      "working on year 1997\n",
      "working on year 1998\n",
      "working on year 1999\n",
      "working on year 2000\n",
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n",
      "working on year 2016\n",
      "working on year 2017\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if santadf.empty:\n",
    "        santadf = small_df\n",
    "    else:\n",
    "        santadf = pd.merge(sonomadf,small_df)\n",
    "santadf.to_csv( 'Santa_Max_Min.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "yakimadf = pd.DataFrame()\n",
    "states = {\n",
    "    'Napa': {\n",
    "        'zip': '95472',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97302',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n",
      "working on year 1993\n",
      "working on year 1994\n",
      "working on year 1995\n",
      "working on year 1996\n",
      "working on year 1997\n",
      "working on year 1998\n",
      "working on year 1999\n",
      "working on year 2000\n",
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n",
      "working on year 2016\n",
      "working on year 2017\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if yakimadf.empty:\n",
    "        yakimadf = small_df\n",
    "    else:\n",
    "        yakimadf = pd.merge(yakimadf,small_df)\n",
    "yakimadf.to_csv( 'Yakima_Max_Min.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dundeedf = pd.DataFrame()\n",
    "states = {\n",
    "#     'Napa': {\n",
    "#         'zip': '95472',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "    'Dundee': {\n",
    "        'zip': '97045',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        },\n",
    "#     'Willamette': {\n",
    "#         'zip': '97302',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n",
      "working on year 1993\n",
      "working on year 1994\n",
      "working on year 1995\n",
      "working on year 1996\n",
      "working on year 1997\n",
      "working on year 1998\n",
      "working on year 1999\n",
      "working on year 2000\n",
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n",
      "working on year 2016\n",
      "working on year 2017\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if dundeedf.empty:\n",
    "        dundeedf = small_df\n",
    "    else:\n",
    "        dundeedf = pd.merge(dundeedf,small_df)\n",
    "dundeedf.to_csv( 'Dundee_Max_Min.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "willamettedf = pd.DataFrame()\n",
    "states = {\n",
    "#     'Napa': {\n",
    "#         'zip': '95472',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Walla': {\n",
    "#         'zip': '99362',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Columbia': {\n",
    "#         'zip': '98813',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Sonoma': {\n",
    "#         'zip': '95476',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Santa': {\n",
    "#         'zip': '95062',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Yakima': {\n",
    "#         'zip': '98903',\n",
    "#         'years':['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "#     'Dundee': {\n",
    "#         'zip': '97045',\n",
    "#         'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "#         },\n",
    "    'Willamette': {\n",
    "        'zip': '97013',\n",
    "        'years': ['1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017']\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 1992\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-2d5006da15d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m#     print(d)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#e = json.loads(p.text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mitems_MAX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'results'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datatype'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'TMAX'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mitems_MIN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'results'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datatype'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'TMIN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# #get the date field from all average temperature readings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'results'"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    small_df = pd.DataFrame()\n",
    "    for year in states[state]['years']:\n",
    "        zip = states[state]['zip']\n",
    "        df_test = pd.DataFrame()\n",
    "        #Print out 'working on year' to idenfity if script is running correctly\n",
    "        print('working on year '+str(year))\n",
    "        #make the api call for temp and precipitation\n",
    "        #r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ZIP:94558&datatypeid=TMIN&sortfield=name&sortorder=desc&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        r = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:{zip}&datatypeid=TMAX&datatypeid=TMIN&units=standard&limit=1000&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token_NOAA})\n",
    "        #p = requests.get(f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=GHCND&limit=1000&stationid=GHCND:USC00046074&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "        #Load JSON data\n",
    "        d = json.loads(r.text)\n",
    "        #     print(d)\n",
    "        #e = json.loads(p.text)\n",
    "        items_MAX = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "        items_MIN = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "        # #get the date field from all average temperature readings\n",
    "        dates_temp_MAX = [item['date'].split('T')[0] for item in items_MAX]\n",
    "        dates_temp_MIN = [item['date'].split('T')[0] for item in items_MIN]\n",
    "        df_test['date'] = dates_temp_MAX\n",
    "        df_test['avgMaxTemp'+state] = np.nan\n",
    "        for item in items_MAX:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMaxTemp'+state]] = item['value']\n",
    "        df_test['avgMinTemp'+state] = np.nan\n",
    "        for item in items_MIN:\n",
    "            date = item['date'].split('T')[0]\n",
    "            df_test.loc[df_test['date'] == date, ['avgMinTemp'+state]] = item['value']\n",
    "        small_df = pd.concat([small_df,df_test])\n",
    "    if willamettedf.empty:\n",
    "        willamettedf = small_df\n",
    "    else:\n",
    "        willamettedf = pd.merge(willamettedf,small_df)\n",
    "willamettedf.to_csv( 'Will_Max_Min.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "willamettedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
